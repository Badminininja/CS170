Welcome to Joseph's Feature Selection Algorithm
Type in the name of the file to test: CS170_Small_Data__55.txt  
Type the number of the algorithm you want to run.
    1) Forward Selection
    2) Backward Elimination
1
This dataset has 6 features (not including the class attribute), with 500 instances.
Running nearest neighbor with all 6 features, using "leaving-one-out" evaluation, I get an accuracy of: 90.6%
Beginning search.
    Using features(s) [1] accuracy is  83.2%
    Using features(s) [2] accuracy is  85.4%
    Using features(s) [3] accuracy is  84.8%
    Using features(s) [4] accuracy is  86.2%
    Using features(s) [5] accuracy is  88.4%
    Using features(s) [6] accuracy is  92.2%
Feature set [6] was best, accuracy is 92.2%
    Using features(s) [6, 1] accuracy is  89.2%
    Using features(s) [6, 2] accuracy is  90.0%
    Using features(s) [6, 3] accuracy is  88.2%
    Using features(s) [6, 4] accuracy is  91.4%
    Using features(s) [6, 5] accuracy is  98.6%
Feature set [6, 5] was best, accuracy is 98.6%
    Using features(s) [6, 5, 1] accuracy is  97.8%
    Using features(s) [6, 5, 2] accuracy is  97.2%
    Using features(s) [6, 5, 3] accuracy is  95.4%
    Using features(s) [6, 5, 4] accuracy is  96.2%
Feature set [6, 5, 1] was best, accuracy is 97.8%
    Using features(s) [6, 5, 1, 2] accuracy is  95.6%
    Using features(s) [6, 5, 1, 3] accuracy is  93.0%
    Using features(s) [6, 5, 1, 4] accuracy is  96.0%
Feature set [6, 5, 1, 4] was best, accuracy is 96.0%
    Using features(s) [6, 5, 1, 4, 2] accuracy is  93.2%
    Using features(s) [6, 5, 1, 4, 3] accuracy is  92.0%
Feature set [6, 5, 1, 4, 2] was best, accuracy is 93.2%
    Using features(s) [6, 5, 1, 4, 2, 3] accuracy is  90.6%
Feature set [6, 5, 1, 4, 2, 3] was best, accuracy is 90.6%

Finished search!! The best feature subset is [6, 5], which has an accuracy of 98.6%